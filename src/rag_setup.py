"""
RAG (Retrieval Augmented Generation) ì„¤ì • ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ë²¡í„°ìŠ¤í† ì–´ë¥¼ êµ¬ì¶•í•˜ë©°,
retriever toolì„ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
from pathlib import Path
from typing import Optional
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.tools import create_retriever_tool
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê¸°ë³¸ ì„¤ì •
DEFAULT_PDF_PATH = "../docs/RAG_document_ver7.pdf"
CHROMA_DB_PATH = "../data/chroma_db"
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 100
TOP_K = 10


def load_pdf_documents(pdf_path: str = DEFAULT_PDF_PATH) -> list:
    """
    PDF íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤.
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ë¶„í• ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ê³„ì‚°
    current_dir = Path(__file__).parent
    
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ ì‹œë„
    possible_paths = [
        pdf_path,
        current_dir / pdf_path,
        current_dir.parent / "RAG_document_ver7.pdf",
        current_dir.parent / "RAG_document_ver6.pdf",
        current_dir.parent / "RAG_document_ver5.pdf",
    ]
    
    pdf_file = None
    for path in possible_paths:
        if Path(path).exists():
            pdf_file = str(path)
            print(f"âœ… PDF íŒŒì¼ ë°œê²¬: {pdf_file}")
            break
    
    if not pdf_file:
        raise FileNotFoundError(
            f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:\n" +
            "\n".join([f"  - {p}" for p in possible_paths])
        )
    
    # PDF ë¡œë“œ
    loader = PyPDFLoader(pdf_file)
    
    # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ìƒì„±
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP
    )
    
    # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
    split_docs = loader.load_and_split(text_splitter)
    
    print(f"ğŸ“„ ì´ {len(split_docs)}ê°œì˜ ë¬¸ì„œ ì²­í¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return split_docs


def create_vectorstore(documents: list, persist_directory: str = CHROMA_DB_PATH) -> Chroma:
    """
    Chroma ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        documents: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        persist_directory: ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ê²½ë¡œ
        
    Returns:
        Chroma ë²¡í„°ìŠ¤í† ì–´ ì¸ìŠ¤í„´ìŠ¤
    """
    # OpenAI API í‚¤ í™•ì¸
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        raise RuntimeError(
            "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
            "RAG ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ .env íŒŒì¼ì— OpenAI API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
        )
    
    # ì„ë² ë”© ëª¨ë¸ ìƒì„±
    embeddings = OpenAIEmbeddings(api_key=openai_api_key)
    
    # Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        persist_directory=persist_directory
    )
    
    print(f"ğŸ—„ï¸ ë²¡í„°ìŠ¤í† ì–´ê°€ {persist_directory}ì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return vectorstore


def load_existing_vectorstore(persist_directory: str = CHROMA_DB_PATH) -> Optional[Chroma]:
    """
    ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        persist_directory: ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ê²½ë¡œ
        
    Returns:
        Chroma ë²¡í„°ìŠ¤í† ì–´ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
    """
    if not Path(persist_directory).exists():
        return None
    
    try:
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            return None
        
        embeddings = OpenAIEmbeddings(api_key=openai_api_key)
        vectorstore = Chroma(
            persist_directory=persist_directory,
            embedding_function=embeddings
        )
        print(f"âœ… ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {persist_directory}")
        return vectorstore
    except Exception as e:
        print(f"âš ï¸ ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def get_retriever_tool(force_rebuild: bool = False):
    """
    Retriever toolì„ ìƒì„±í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        force_rebuild: Trueì¼ ê²½ìš° ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ êµ¬ì¶•
        
    Returns:
        LangChain retriever tool
    """
    # ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ í™•ì¸
    vectorstore = None
    if not force_rebuild:
        vectorstore = load_existing_vectorstore()
    
    # ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if vectorstore is None:
        print("ğŸ“š ìƒˆë¡œìš´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤...")
        try:
            documents = load_pdf_documents()
            vectorstore = create_vectorstore(documents)
        except FileNotFoundError as e:
            print(f"âš ï¸ {e}")
            print("âš ï¸ RAG ê¸°ëŠ¥ ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            return None
        except RuntimeError as e:
            print(f"âš ï¸ {e}")
            return None
    
    # Retriever ìƒì„±
    retriever = vectorstore.as_retriever(search_kwargs={"k": TOP_K})
    
    # Retriever Tool ìƒì„±
    retriever_tool = create_retriever_tool(
        retriever,
        name='pdf_search',
        description='Use this tool to search information from PDF document about technical analysis indicators and stock trading terms'
    )
    
    print("âœ… Retriever toolì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return retriever_tool


def rebuild_vectorstore():
    """ë²¡í„°ìŠ¤í† ì–´ë¥¼ ê°•ì œë¡œ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤."""
    print("ğŸ”„ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì¬êµ¬ì¶•í•©ë‹ˆë‹¤...")
    
    # ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ì‚­ì œ
    import shutil
    if Path(CHROMA_DB_PATH).exists():
        shutil.rmtree(CHROMA_DB_PATH)
        print(f"ğŸ—‘ï¸ ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤: {CHROMA_DB_PATH}")
    
    # ìƒˆë¡œ êµ¬ì¶•
    return get_retriever_tool(force_rebuild=True)


if __name__ == "__main__":
    """
    ì§ì ‘ ì‹¤í–‰ ì‹œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    
    ì‚¬ìš©ë²•:
        python rag_setup.py
    """
    print("=" * 60)
    print("RAG ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì‹œì‘")
    print("=" * 60)
    
    try:
        # ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•
        retriever_tool = rebuild_vectorstore()
        
        if retriever_tool:
            print("\n" + "=" * 60)
            print("âœ… RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("=" * 60)
            
            # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
            print("\nğŸ§ª í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
            test_query = "RSIê°€ ë­ì•¼?"
            result = retriever_tool.invoke(test_query)
            print(f"\nê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ {min(3, len(result))}ê°œ):")
            for i, doc in enumerate(result[:3], 1):
                print(f"\n[ë¬¸ì„œ {i}]")
                print(doc[:200] + "..." if len(doc) > 200 else doc)
        else:
            print("\nâš ï¸ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

